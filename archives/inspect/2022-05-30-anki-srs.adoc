---
layout: post-inspect
title: Anki SRS Algorithm
subtitle: Spaced Repetition Explained with Code
author: Julien Sobczak
date: '2022-05-30'
category: inspect
subject: Anki
tags:
  - learning
unofficialTags:
  - flashcards
excerpt: >
  Forgetting is key to learning. Forgetting is what separates what is useful and what is not. Sometimes, we want to make a piece of knowledge stick in memory despite what our memory thinks. Spaced Repetition is an effective solution to this problem and Anki is the most popular OSS tool to help you. In this post, you will discover how Anki works under the hood to help you review your cards at optimum intervals and ensure they stay in your memory for a long time.
excerpt_only: true
recommendations:
  - 2020-12-26-anki-scripting-for-non-programmers
---

:page-liquid:
:tabsize: 4
:imagesdir: {{ '/posts_resources/2022-05-30-anki-srs/' | relative_url }}
:icons: font

[quote, Hermann Ebbinghaus, German Psychologist having introduced the Forgetting Curve]
____
Humans more easily remember or learn items when they are studied a few times over a long period of time (spaced presentation), rather than studied repeatedly in a short period of time.
____


[.lead]
Forgetting is key to learning. Forgetting is what separates what is useful and what is not. Sometimes, we want to make a piece of knowledge stick in memory despite what our memory thinks. Spaced Repetition is an effective solution to this problem and Anki is the most popular OSS tool to help you.


[TIP.content]
.What You Will Learn
====
* What is the history of SRS algorithms.
* How Anki SRS algorithm is implemented.
* How Anki SRS algorithm differs from other known implementations.
* How Anki SRS algorithm can be improved.
====

[CAUTION.license]
The Anki source code is published under link:https://www.gnu.org/licenses/agpl-3.0.en.html[AGPL v3]. The code presented in this article has been slightly adapted for learning and readability purposes.

[NOTE]
.Prerequisites
====
I assume that you have used Anki before. All code examples use the Python language, mainly because Anki was implemented only in Python until recently, and also because it's a great language for novice programmers. You don't need to have a solid understanding of the language to follow the article as the code uses basic Python syntax.
====


== SRS Primer

The role of any Spaced Repetition System (SRS) algorithm is to determine what the user should review now, or say differently when must happen the next review for every remembered item. *The goal of any implementation is to counteract the effect of the forgetting curve*:

image::forgetting-curve.png[width=750, link="/posts_resources/2022-05-30-anki-srs/forgetting-curve.png"]

As soon as we learn or review a piece of knowledge, the decay begins. SRS algorithms need to determine the optimal interval between two reviews to ensure we haven't completely forgotten it (memory retention = 0%) while trying to limit as much as possible the number of reviews. In practice, most algorithms use 10% for the forgetting index (= 90% of items are remembered correctly) so that we don't have too many items to review again while keeping the number of reviews close to optimal.

The details of the different algorithms differ greatly between systems. We will start by reviewing the most popular ones in history before introducing Anki's solution.


=== The Leitner System (1970-)

If link:https://en.wikipedia.org/wiki/Hermann_Ebbinghaus[Hermann Ebbinghaus] is credited for the initial research behind SRS, the link:https://en.wikipedia.org/wiki/Leitner_system[Leiter System] is often quoted as the first algorithm. This system uses a physical box as depicted by the following illustration:

image::Leitner-original.png[width=500, link="/posts_resources/2022-05-30-anki-srs/Leitner-original.png"]

Here is a small Python program implementing the logic behind the original Leitner system:

[source,python]
----
from queue import Queue
import random

CARDS_PER_CM = 5

BOX = [
    Queue(1  * CARDS_PER_CM),
    Queue(2  * CARDS_PER_CM),
    Queue(5  * CARDS_PER_CM),
    Queue(8  * CARDS_PER_CM),
    Queue(14 * CARDS_PER_CM),
]

def add(card, i):
    BOX[i].put(card)
    if BOX[i].full():
        study()

def review(card):
    return random.choice([True, True, True, False])

def study():
    for index, partition in enumerate(BOX):
        if partition.full():
            # Time to review the cards
            print(f"Time to study partition {index + 1}!")

            cards_to_review = []
            while not partition.empty():
                cards_to_review.append(partition.get())

            for card in cards_to_review:
                answer = review(card)
                new_index = None
                if answer and index + 1 < len(BOX):
                    # Promote
                    new_index = index + 1
                elif not answer and index - 1 > 0:
                    # Demote
                    new_index = 0
                else:
                    # Replace in the same partition
                    new_index = index
                add(card, new_index)

if __name__ == "__main__":

    # Populate the box
    for i in range(140):
        add("New Card", 0)

    # Study
    study()
----

The original Leitner system cannot really be considered a spaced repetition system. There is no concept of an (optimum) interval. The system simply prioritizes which items to review based on the available physical space in each partition.

An alternative method using three boxes where incorrect answers are only moved back to the previous box is often privileged:

image::Leitner-modern.png[width=700, link="/posts_resources/2022-05-30-anki-srs/Leitner-modern.png"]

Here is a program implementing this new logic:

[source,python]
----
from queue import Queue
import random
from datetime import datetime, timedelta

A = 0
B = 1
C = 2
SYSTEM = [
    Queue(), # Box A: every day
    Queue(), # Box B: every 2-3 days (ex: Tuesday & Friday)
    Queue(), # Box C: every week (ex: Sunday)
]


def add(card, i):
    """Add a new card in the Leitner system."""
    SYSTEM[i].put(card)

def review(card):
    """Answer a single card."""
    return random.choice([True, True, True, False])

def study_box(number):
    """Review all cards in a box."""
    cards_to_review = []
    while not SYSTEM[number].empty():
        cards_to_review.append(SYSTEM[number].get())

    for card in cards_to_review:
        answer = review(card)
        new_number = None
        if answer and number < C:
            # Promote
            new_number = number + 1
        elif not answer and number > A:
            # Demote
            new_number = number - 1
        else:
            # Replace in the same box
            new_number = number
        add(card, new_number)

def study(day):
    """Study the box according the week day."""
    weekday = day.weekday()
    if weekday == 0: # Monday
        study_box(A)
    elif weekday == 1: # Tuesday
        study_box(A)
        study_box(B)
    elif weekday == 2: # Wednesday
        study_box(A)
    elif weekday == 3: # Thursday
        study_box(A)
    elif weekday == 4: # Friday
        study_box(A)
        study_box(B)
    elif weekday == 5: # Saturday
        study_box(A)
    elif weekday == 6: # Sunday
        study_box(A)
        study_box(C)

if __name__ == "__main__":

    # Populate the box
    for i in range(140):
        add("New Card", 0)

    # Study (over 10 days)
    for i in range(10):
        day = datetime.today() - timedelta(days=10 - i)
        study(day)
----

The modern Leitner system assigns intervals to the different boxes. Variants exist with more boxes but for this system to be considered a spaced repetition system, we would need a lot more boxes to have longer and longer intervals between reviews.


=== SM-0 (1985)

Algorithms are precise instructions to carry out. As we have seen with the Leitner system, algorithms don't have to be executed on computers at all. We can manually perform what a computer does, except we will need a lot more time. The first version of the SuperMemo Algorithm was also thought to be executed manually.

The link:http://super-memory.com/articles/paper.htm[SM-0 algorithm] (aka the paper-and-pencil SuperMemo method) was published in 1985 and relies on link:http://super-memory.com/articles/paper.htm[paper books filled with tables].

image::sm-0.png[width=800, link="/posts_resources/2022-05-30-anki-srs/sm-0.png"]

Although the algorithm was designed to be executed manually, we can still capture the logic using code:

[source,python]
----
import random
from datetime import date, timedelta
from queue import Queue

# The table of repetition intervals determines the number of days between
# two successive reviews.
# SM-0 applies the factor 1.7 between two successive values.
# Ex: 4, 7, 12, 20, ...
TABLE_REPETITION_INTERVALS = [4] # First review after 4 days
for i in range(1, 15): # 15 repetitions max
    prev = TABLE_REPETITION_INTERVALS[i - 1]
    next = int(prev * 1.7)
    TABLE_REPETITION_INTERVALS.append(next)

# The book containing the pages to review
DATABOOK = []
# The book containing the page numbers to review day after day
# NB: We use a sparse dictionary where only dates
# with one or more pages to review are present
SCHEDULE_BOOK = {} # <date, [page numbers]>

# Fake the user in answering the question
def review_question(question, repetitions):
    """
    Randomly answer a question.
    The chance of answering correctly increases with the number of repetitions.
    """
    return random.choice([True] * repetitions * 4 + [False])

# A single page in the data book.
class Page:

    def __init__(self, questions, answers):
        # "Question field" column
        self.questions = questions
        # "Answer field" column
        self.answers = answers
        # "Repetition scores" column
        # => Determined during the review session
        # "Repetitions" column
        self.repetitions = []

    def review(self):
        remaining_questions = Queue(self.questions)

        # Review until there is no more cards wrongly answered
        iteration = 1
        # Memorize the number of wrong answers during the first iteration
        U = 0
        while not remaining_questions.empty():

            questions_to_review = []
            while not remaining_questions.empty():
                questions_to_review.append(remaining_questions.get())

            for question in questions_to_review:
                if not review_question(question, iteration): # <1>
                    # Review again
                    remaining_questions.append(question)
                    if iteration == 1:
                        U += 1
            iteration += 1

        self.repetitions.append({
            "No": len(self.repetitions) + 1,
            "Dat": str(date.today()),
            "U": U,
        })


if __name__ == "__main__":
    # Add a new page for illustration purposes
    DATABOOK.append(Page(
        questions=["Question 1", "Question 2", "Question 3"],
        answers=["Answer 1", "Answer 2", "Answer 3"],
    ))
    page_number = len(DATABOOK) - 1

    # Mark the page to review according the table of repetition intervals
    now = date.today()
    for interval in TABLE_REPETITION_INTERVALS:
        review_date = str(now + timedelta(days=interval))
        if review_date not in SCHEDULE_BOOK:
            SCHEDULE_BOOK[review_date] = []
        print(f"Page {page_number} to review on {review_date}")
        SCHEDULE_BOOK[review_date] = [page_number]

    # Review sessions during one year
    for i in range(365):
        day = str(now + timedelta(days=i))
        if not day in SCHEDULE_BOOK:
            # Nothing to review today
            continue
        # Review each planned pages
        for page in SCHEDULE_BOOK[day]:
            print(f"Reviewing page {page} on {day}")
            DATABOOK[page].review()
----
<1> The grade of the answer does not influence the next interval. Difficult items are reviewed again the same day but the next intervals are fixed and determined with a factor 1.7 when creating the page.

The SM-0 algorithm can be challenging in practice for different reasons:

* **All items on a given page are reviewed at the same time**. For hard-to-remember items (items that require more than 3 reviews on a given day to be recalled), SM-0 recommends duplicating them on a new page in your book. These items will be reviewed more frequently, and some will maybe be duplicated again if still too hard to remember.
* **The intervals are determined using an estimation of the average case** (x1.7) but the ideal intervals depend on the complexity and your familiarity with the subject. You probably need shorter intervals for science subjects like Mathematics for example.
* Last but not least, executing the algorithm manually works, but is far from being a smooth learning experience...

Enter the computer.


=== SM-2 (1987)

Unlike physical systems where cards are grouped in the same box/partition/page and are reviewed collectively, digital systems consider each item separately. For example, the SuperMemo algorithm called link:https://www.supermemo.com/en/archives1990-2015/english/ol/sm2[SM-2] assigns a specific level of difficulty to every card and determines the appropriate intervals between repetitions using this specific value (called the E-Factor).

image::sm-2.png[width=800, link="/posts_resources/2022-05-30-anki-srs/sm-2.png"]

Now, the same logic but implemented as code:

[source,python]
----
import random
from datetime import date, timedelta
from queue import Queue

def grade(question, repetitions):
    # Increase the chance of success with the increased number of repetitions
    choices = [0] * 1 * repetitions + [1] * 2 * repetitions + \
              [2] * 3 * repetitions + [3] * 4 * repetitions + \
              [4] * 5 * repetitions + [5] * 6 * repetitions
    return random.choice(choices)

# Settings
I1 = 1
I2 = 6
MIN_EF = 1.3 # <1>

class Item:

    def __init__(self, question, answer):
        self.question = question
        self.answer = answer
        self.EF = 2.5 # <2>
        self.I = I1
        self.next_review = date.today() + timedelta(days=self.I)
        self.repetitions = 0

    def review(self, day, q):
        self.EF = max(self.EF+(0.1-(5-q)*(0.08+(5-q)*0.02)), MIN_EF) # <3>
        if q < 3:
            self.I = I1
        elif self.I == I1:
            self.I = I2
        else:
            self.I = round(self.I * self.EF)
        self.next_review = day + timedelta(days=self.I)
        self.repetitions += 1
        return q < 4

if __name__ == "__main__":
    # Populate items
    items = []
    for i in range(1, 100):
        items.append(Item(f"Q{i}", f"A{i}"))

    # Review one year
    # for i in range(365):
    for i in range(365):
        day = date.today() + timedelta(days=i)

        items_to_review = Queue()
        for item in items:
            if item.next_review == day:
                items_to_review.put(item)

        while not items_to_review.empty():
            item = items_to_review.get()
            q = grade(item.question, item.repetitions + 1)
            if not item.review(day, q): # <4>
                items_to_review.put(item)
----
<1> The E-Factor never goes down lower than 1.3. SuperMemo found out that items having lower E-Factors were repeated annoyingly often when the root cause was usually their formulation and not the review process. We will see how Anki manages such cards later. These items must often be reformulated to conform to the link:https://supermemo.guru/wiki/Minimum_information_principle[minimum information principle].
<2> The E-Factor is always initialized to the same difficulty value. It will decrease for bad grades and increase for good grades.
<3> Unlike SM-0, the grades (= item difficulty) influence the factor used to determine the next interval.
<4> Like SM-0, difficult items are reviewed again the same day.

The SM-2 algorithm, while relatively basic, remains popular even today as you will discover in the rest of this article.


== Anki Algorithm

From link:https://en.wikipedia.org/wiki/Anki_(software)[Wikipedia]:

[quote,Wikipedia]
____
"The SM-2 algorithm, created for SuperMemo in the late 1980s, forms the basis of the spaced repetition methods employed in the program. Anki's implementation of the algorithm has been modified to allow priorities on cards and to show flashcards in order of their urgency.
____


Anki source code includes different versions of its SRS algorithm (called _Scheduler_). All got inspiration from SM-2. The link:https://faqs.ankiweb.net/the-anki-2.1-scheduler.html[V2] is in use since 2018 even if the link:https://faqs.ankiweb.net/the-2021-scheduler.html[V3] is looming. For this article, we can ignore the details between these versions. Check the source code on GitHub if you are interested in the differences between the link:https://github.com/ankitects/anki/blob/2.1.49/pylib/anki/scheduler/v1.py[V1], link:https://github.com/ankitects/anki/blob/2.1.49/pylib/anki/scheduler/v2.py[V2], or link:https://github.com/ankitects/anki/blob/2.1.49/pylib/anki/scheduler/v3[V3].


We will analyze the V2.1 scheduler as it is the version I'm familiar with. We will use the link:https://github.com/ankitects/anki/blob/2.1.10/anki/schedv2.py[version 2.10.0] of Anki Desktop to ignore recent refactorings (the rewrite of backend code in Rust, the introduction of Protocol Buffer messages, the factorization of common code among scheduler versions using inheritance, etc.). This will help us keep the code easy to grasp.

Here is a recall of link:https://docs.ankiweb.net/getting-started.html#key-concepts[Anki terminology]:

image::anki-terminology.png[width=750, link="/posts_resources/2022-05-30-anki-srs/anki-terminology.png"]

As outlined by the schema, we will focus on the core abstractions (Collection, Note, Card) that affects how the SRS algorithm works. In addition, cards in Anki are scheduled differently according to their state:

image::anki-workflow.png[width=700, link="/posts_resources/2022-05-30-anki-srs/anki-workflow.png"]

Here is an overview of the Anki algorithm:

image::anki-srs.png[width=750, link="/posts_resources/2022-05-30-anki-srs/anki-srs.png"]

The use of separate new/review queues tries to remediate a common complaint with the standard SM-2 algorithm is that repeated failings of a card cause the card to get stuck in "low interval hell" (also known as "ease hell"). link:https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html#review-cards[In Anki], the initial acquisition process does not influence the ease factor.


### Part 1: Settings

Unlike previous systems, Anki is highly configurable. Not all settings affect the SRS algorithm. Here are the default setting values used by Anki that will be used:

[source,python]
----

# Whether new cards should be mixed with reviews, or shown first or last
NEW_CARDS_DISTRIBUTE = 0
NEW_CARDS_LAST = 1
NEW_CARDS_FIRST = 2

# The initial factor when a card gets promoted
STARTING_FACTOR = 2500

# Default collection configuration
colConf = {
    'newSpread': NEW_CARDS_DISTRIBUTE,
    'collapseTime': 1200, # <1>
}

# Default deck configuration
deckConf = {
    'new': { # <2>
        'delays': [1, 10],
        'ints': [1, 4],
        'initialFactor': STARTING_FACTOR,
        'perDay': 20,
    },
    'rev': { # <2>
        'perDay': 200,
        'ease4': 1.3,
        'maxIvl': 36500,
        'hardFactor': 1.2,
    },
    'lapse': { # <3>
        'delays': [10],
        'mult': 0,
        'minInt': 1,
        'leechFails': 8,
    },
}
----
<1> If there is no more card to review now but the next card in learning is in less than `collapseTime` seconds, show it now. +
  * `collapseTime`: Tells Anki how to behave when there is nothing left to study in the current deck but cards in learning. +
    _Setting_: `Preferences` > `Basic` > `Learn ahead limit` * 60 (default: `20` minutes)
<2> The settings differ based on the queue where a card belongs. For example, when learning (`new`) cards, the delay is increased by graduating steps whereas the delay is multiplied by a given factor for review (`rev`) cards. The meaning of individual settings will become clearer when we will detail the logic. +
  * `new.delays`: The list of successive delays between the learning steps of the new cards. The first delay will be used when you press the `Again` button on a new card. The `Good` button will advance to the next step. Once all steps have been passed, the card will become a review card and will appear on a different day. +
    _Setting_: `Preferences` > `New Cards` > `Learning steps` (Default: `1m 10m`)
  * `new.ints`: The list of delays according to the button pressed while leaving the learning mode after pressing "Good" or "Easy." +
    _Setting_: `Preferences` > `New Cards` > `Graduating interval`/`Easy interval` (Default: `1` and `4`)
  * `new.initialFactor`: The ease multiplier new cards start with. By default, the `Good` button on a newly-learned card will delay the next review by 2.5x the previous delay. +
    _Setting_: `Preferences` > `Advanced` > `Starting ease` (Default: `2.50`),
  * `new.perDay`: The maximum number of new cards to introduce in a day, if new cards are available. +
    _Setting_: `Preferences` > `Daily Limits` > `New cards/day` (Default: `20`)
  * `rev.perDay`: The maximum number of review cards to show in a day, if cards are ready for review. +
    _Setting_: `Preferences` > `Daily Limits` > `Maximum reviews/day` (Default: `50`)
  * `rev.ease4`: An extra multiplier that is applied to a review card's interval when you rate it `Easy`. +
    _Setting_: `Preferences` > `Advanced` > `Easy bonus` (Default: `1.30`)
  * `rev.maxIvl`: The maximum number of days a review card will wait. When reviews have reached the limit, `Hard`, `Good` and `Easy` will all give the same delay. +
    _Setting_: `Preferences` > `Advanced` > `Maximum interval` (Default: `36500`)
  * `rev.hardFactor`: The multiplier applied to a review interval when answering `Hard`. +
    _Setting_: `Preferences` > `Advanced` > `Hard interval` (Default: `1.20`)
<3> When you forget a review card, it is said to have "lapsed", and the card must be relearnt. The default behavior for lapsed reviews is to reset the interval (`minInt`) to 1 (i.e. make it due tomorrow) and put it in the learning queue for a refresher (`delays`) in 10 minutes. +
  * `lapse.delays`: The list of successive delays between the learning steps of lapsed cards. By default, pressing the `Again` button on a review card will show it again 10 minutes later. +
    _Setting_: `Preferences` > `Lapses` > `Relearning steps` (Default: `10m`)
  * `lapse.minInt`: The minimum interval given to a review card after answering `Again`. +
    _Setting_: `Preferences` > `Lapses` > `Minimum interval` (Default: `1`)
  * `lapse.mult`: The multiplier applied to a review interval when answering `Again`. +
    _Setting_: `Preferences` > `Advanced` > `New interval` (Default: `0`)
  * `lapse.leechFails`: The number of times `Again` needs to be pressed on a review card before it is marked as a leech. +
    _Setting_: `Preferences` > `Lapses` > Leech threshold (Default: `8`)


### Part 2: Model

Let's begin with the model. Anki stores cards in an SQLite database. In this tutorial, we will mimic the same model but we will store the cards directly in memory inside the collection object. We will also ignore decks completely as they mostly allow reviewing different cards using different settings or at different times but don't profoundly change how Anki works.


[source,python]
----
class Collection:

    def __init__(self, id=None):
        d = datetime.datetime.today()
        d = datetime.datetime(d.year, d.month, d.day)
        # Timestamp of the creation date in seconds.
        self.crt = int(time.mktime(d.timetuple()))
        # In-memory list of cards
        self.cards = []
        self.sched = Scheduler(self) # <1>

    def addNote(self, note):
        self.cards.append(Card(note))

class Note:

    def __init__(self):
        self.id = intId() # <2>
        self.tags = []

    def addTag(self, tag):
        if not tag in self.tags:
            self.tags.append(tag)

class Card:

    def __init__(self, note, id=None):
        self.id = intId() # <2>
        self.note = note
        # Timestamp of the creation date in second.
        self.crt = intTime()
        # 0=new, 1=learning, 2=review, 3=relearning
        self.type = 0
        # Queue type:
        #   -1=suspend => leeches (as manual suspension is not supported)
        #    0=new     => new (never shown)
        #    1=lrn     => learning/relearning
        #    2=rev     => review (as for type)
        self.queue = 0
        # The interval. Negative = seconds, positive = days
        self.ivl = 0
        # The ease factor in permille.
        # Ex: 2500 = the interval will be multiplied by 2.5
        # the next time you press "Good".
        self.factor = 0
        # The number of reviews.
        self.reps = 0
        # The number of times the card went from a "was answered correctly"
        # to "was answered incorrectly" state.
        self.lapses = 0
        # Of the form a*1000+b, with:
        #   a => the number of reps left today
        #   b => the number of reps left till graduation
        # Ex: '2004' = 2 reps left today and 4 reps till graduation
        self.left = 0
        # Due is used differently for different card types:
        # - new => note id or random int
        # - lrn => integer timestamp in second
        # - rev => integer day, relative to the collection's creation time
        self.due = self.id
----
<1> The `Scheduler` implementation will be the main topic of the remaining of this section.
<2> The identifiers are initialized using a helper function `intId()` which uses the current time and ensures two successive calls return different values. Here is the definition:

[source,python]
----
import time

def intId():
    """Returns a unique integer identifier."""
    t = intTime(1000)
    # Make sure the next call to the function returns a different value
    while intTime(1000) == t:
        time.sleep(1)
    return t

def intTime(scale=1):
    "The time in integer seconds. Pass scale=1000 to get milliseconds."
    return int(time.time()*scale)
----

The `Scheduler` is the largest class that will be covered. A scheduler in Anki is an object supporting two methods:

* `getCard()`: Returns the next card to review
* `answerCard(card, ease)`: Updates the card after an answer (`ease`: `0` for "Again", `1` for "Hard", `2` for "Good", and `3` for "Easy")

[source,python]
----
class Scheduler:

    def __init__(self, col):
        # The collection used to retrieve the cards
        self.col = col
        # An upper limit for new and review cards
        self.queueLimit = 50
        # An upper limit for learning cards
        self.reportLimit = 1000
        # The number of already reviewed cards today
        self.reps = 0
        # The number of days since the collection creation
        self.today = self._daysSinceCreation() # <1>
        # The timestamp of the end of day
        self.dayCutoff = self._dayCutoff() # <2>
        # The timestamp in seconds to determine the learn ahead limit
        self._lrnCutoff = 0 # <3>
        self.reset()
----
<1> The attribute `today` represents the number of days since the collection creation. It is used when searching for review cards where the attribute `due` represents the number of days relative to it. The value is initialized like this:
+
[source,python]
----
class Scheduler:

    def _daysSinceCreation(self):
        startDate = datetime.datetime.fromtimestamp(self.col.crt)
        return int((time.time() - time.mktime(startDate.timetuple())) // 86400)
        # Note: 86400s = 1d
----
<2> The attribute `dayCutoff` represents the timestamp of the beginning of the next day. Anki allows customizing at which hour a day ends. Here, we simply use midnight:
+
[source,python]
----
class Scheduler:

    def _dayCutoff(self):
        date = datetime.datetime.today()
        date = date.replace(hour=0, minute=0, second=0, microsecond=0)
        if date < datetime.datetime.today():
            date = date + datetime.timedelta(days=1)
        stamp = int(time.mktime(date.timetuple()))
        return stamp
----
<3> The attribute `_lrnCutoff` is related to the setting `collapseTime` (also called the learn ahead limit). The method `_updateLrnCutoff()` is used to initialize it and update it:
+
[source,python]
----
class Scheduler:

    def _updateLrnCutoff(self, force):
        nextCutoff = intTime() + self.col.colConf['collapseTime']
        if nextCutoff - self._lrnCutoff > 60 or force:
            self._lrnCutoff = nextCutoff
            return True
        return False
----


### Part 3: Queues Management

The method `reset()` present in the last line of the `Scheduler`'s constructor initializes the queues managed by Anki:

[source,python]
----
class Scheduler:

    def reset(self):
        self._resetLrn()
        self._resetRev()
        self._resetNew()

    # New cards
    #################################################################

    def _resetNew(self):
        self._newQueue = [] # <1>
        self._updateNewCardRatio() # <2>

    def _fillNew(self):
        if self._newQueue:
            return True
        lim = min(self.queueLimit, deckConf["new"]["perDay"])
        self._newQueue = list(filter(lambda card: card.queue == 0,
            self.col.cards)) # <3>
        self._newQueue.sort(key=lambda card: card.due)
        self._newQueue = self._newQueue[:lim]
        if self._newQueue:
            return True

    def _updateNewCardRatio(self):
        if colConf['newSpread'] == NEW_CARDS_DISTRIBUTE:
            if self._newQueue:
                newCount = len(self._newQueue)
                revCount = len(self._revQueue)
                self.newCardModulus = (
                    (newCount + revCount) // newCount)
                # if there are cards to review, ensure modulo >= 2
                if revCount:
                    self.newCardModulus = max(2, self.newCardModulus)
                return
        self.newCardModulus = 0 # = Do not distribute new cards


    # Learning cards
    #################################################################

    def _resetLrn(self):
        self._updateLrnCutoff(force=True)
        self._lrnQueue = [] # <1>

    def _fillLrn(self):
        if self._lrnQueue:
            return True
        cutoff = intTime() + colConf['collapseTime']
        self._lrnQueue = list(filter(lambda card: card.queue == 1 and
            card.due < cutoff, self.col.cards)) # <4>
        self._lrnQueue.sort(key=lambda card: card.id)
        self._lrnQueue = self._lrnQueue[:self.reportLimit]
        return self._lrnQueue

    # Review cards
    #################################################################

    def _resetRev(self):
        self._revQueue = [] # <1>

    def _fillRev(self):
        if self._revQueue:
            return True
        lim = min(self.queueLimit, self.col.deckConf["rev"]["perDay"])
        self._revQueue = list(filter(lambda card: card.queue == 2 and
            card.due <= self.today, self.col.cards)) # <5>
        self._revQueue.sort(key=lambda card: card.due)
        self._revQueue = self._revQueue[:lim]

        if self._revQueue:
            r = random.Random()
            r.seed(self.today)
            r.shuffle(self._revQueue)
            return True

----
<1> By default, the queues are empty. Anki defers their filling until a card is retrieved.
<2> The method `_updateNewCardRatio()` determines the frequency for new cards (only when new cards are spread among other cards). For example, if there are 50 review cards and 10 new cards, the ratio will be 5 so that a new card is returned after every 5 review cards. The attribute `reps` present in `Scheduler` keeps the current number of reviewed cards for the current study session and will be useful when using the ratio `_newCardModulus` to determine if the next card must be a new card or a review card.
<3> Anki searches for all cards in the queue `0` (= `new`) and sorts them by their due date before returning the first N cards based on the current daily limit.
<4> Anki searches for all cards in the queue `1` (= `lrn`) that are due and sorts them by timestamp as the id is initialized from the creation timestamp
<5> Anki searches for all cards in the queue `2` (= `rev`) that are due and sorts them by the due date before returning the first N shuffled cards based on the current daily limit.


The logic to initialize the queues is ready but will be executed in the next step when retrieving a card to study.

### Part 4: Card Retrieving

The main method is the method `getCard()`.

[source,python]
----
class Scheduler:

    def getCard(self):
        card = self._getCard()
        if card:
            self.reps += 1
            return card
----

This method delegates to `_getCard()` and simply increases the counter of studied cards except when the study session is completed.

[source,python]
----
class Scheduler:

    def _getCard(self): # <1>
        "Return the next due card or None."

        # learning card due?
        c = self._getLrnCard()
        if c:
            return c

        # new first, or time for one?
        if self._timeForNewCard():
            c = self._getNewCard()
            if c:
                return c

        # card due for review?
        c = self._getRevCard()
        if c:
            return c

        # new cards left?
        c = self._getNewCard()
        if c:
            return c

        # collapse or finish
        return self._getLrnCard(collapse=True)


    # New cards
    ##########################################################################

    def _getNewCard(self):
        if self._fillNew(): # <2>
            return self._newQueue.pop()

    def _timeForNewCard(self):
        "True if it's time to display a new card when distributing."
        if not self._newQueue:
            return False
        if colConf['newSpread'] == NEW_CARDS_LAST:
            return False
        elif colConf['newSpread'] == NEW_CARDS_FIRST:
            return True
        elif self.newCardModulus:
            return self.reps and self.reps % self.newCardModulus == 0


    # Learning queues
    ##########################################################################

    def _getLrnCard(self, collapse=False):
        if self._fillLrn(): # <2>
            return self._lrnQueue.pop()

    # Reviews
    ##########################################################################

    def _getRevCard(self):
        if self._fillRev(): # <2>
            return self._revQueue.pop()
----
<1> By default, Anki shows cards in a well-defined order:
+
. New cards when `newSpread == NEW_CARDS_FIRST`
. Learning cards that are due
. New cards when `newSpread == NEW_CARDS_DISTRIBUTE` (default)
. Review cards
. New cards when `newSpread == NEW_CARDS_LAST`
<2> The methods `_fillXXX()` return `True` when a queue is not empty, in which case, we simply have to pop an element from it.

The queues are now initialized when retrieving the first card in each of them. This works great for the current session but when a new day begins, Anki must reinitialize the queues because other cards may have reached their due date.

[source,python,linenums,highlight='4,9-14,16-19,22']
----
class Scheduler:

    def reset(self):
        self._updateCutoff() # <1>
        self._resetLrn()
        self._resetRev()
        self._resetNew()

    def _updateCutoff(self):
        # days since col created
        self.today = self._daysSinceCreation()
        # end of day cutoff
        self.dayCutoff = self._dayCutoff()
        return stamp

    def _checkDay(self):
        # check if the day has rolled over
        if time.time() > self.dayCutoff:
            self.reset()

    def getCard(self):
        self._checkDay() # <2>
        card = self._getCard()
        if card:
            self.reps += 1
            return card

----
<1> The method `_updateCutoff()` is called every time the queues are reset (= once a day). When this happens, it means a new day began and therefore the day limit must be refreshed too.
<2> The method `_checkDay()` is called every time we retrieve a new card to study. This way, if we have passed the current day, the queue will be reset before returning the next card.



### Part 5: Card Updating

Now that we have a method to empty the list of cards to study, we will turn our attention to the core part of the SRS algorithm. Every time we study a card, the card must be rescheduled. In short, we need to update the attribute `due` (= the next review date) of the card but the logic varies according to its current state (ex: the current queue, ease factor, and interval).

[source,python]
----
class Scheduler:

    def answerCard(self, card, ease):
        assert 1 <= ease <= 4
        assert 0 <= card.queue <= 4

        card.reps += 1

        if card.queue == 0:
            self._answerNewCard(card, ease)
        elif card.queue in [1, 3]:
            self._answerLrnCard(card, ease)
        elif card.queue == 2:
            self._answerRevCard(card, ease)
        else:
            assert 0
----

We will detail each case separately.

### Part 5.1: Answering New Cards

[source,python]
----
class Scheduler:

    def _answerNewCard(self, card, ease):
        # came from the new queue, move to learning
        card.queue = 1 # <1>
        card.type = 1 # <2>
        # init reps to graduation
        card.left = self._startingLeft(card) # <3>

    def _startingLeft(self, card):
        conf = self._lrnConf(card)
        tot = len(conf['delays'])
        tod = self._leftToday(conf['delays'], tot)
        return tot + tod*1000

    def _leftToday(self, delays, left, now=None):
        "The number of steps that can be completed by the day cutoff."
        if not now:
            now = intTime()
        delays = delays[-left:]
        ok = 0
        for i in range(len(delays)):
            now += delays[i]*60
            if now > self.dayCutoff:
                break
            ok = i
        return ok+1
----
<1> Anki simply updates the attribute `queue` to move a card to a different queue. When the destination queue will be reset (ex: for tomorrow's session), the card will be automatically inserted into it.
<2> The attribute `type` is similar to the attribute `queue` (they share the same values `0`, `1`, and `2`). In practice, the attributes `queue` and `type` may differ for example after a lapse. When pressing "Again," on a review card, the card will be moved back to the learning back (`queue = 1`) but the type will be unchanged (`type = 2`) to remember the card was previously a review card. This will be useful when graduating the card back to the review queue after relearning.
<3> The attribute `left` is particular. The numeric format keeps two pieces of information: how many times the card will be reviewed today, and how many steps before graduation. The methods `_startingLeft` and `_leftToday` implement this logic. You can safely ignore the details.


So, when answering a new card, the card is automatically promoted to the learning queue.

### Part 5.2: Answering Learning Cards

[source,python]
----
class Scheduler:

    def _answerLrnCard(self, card, ease):
        conf = self._lrnConf(card) # <1>

        # immediate graduate?
        if ease == 4:
            self._rescheduleAsRev(card, conf, True)
        # next step?
        elif ease == 3:
            # graduation time?
            if (card.left%1000)-1 <= 0:
                self._rescheduleAsRev(card, conf, False)
            else:
                self._moveToNextStep(card, conf)
        elif ease == 2:
            self._repeatStep(card, conf)
        else:
            # back to first step
            self._moveToFirstStep(card, conf)

    def _lrnConf(self, card):
        if card.type == 2:
            return self.col.deckConf["lapse"]
        else:
            return self.col.deckConf["new"]
----
<1> The settings differ according to if the card comes from the review or new queue. For example, the steps are different after a lapse than when learning a new card for the first time.

We will detail what happens depending on which button was pressed when answering the card.


#### After pressing "Again"...

[source,python]
----
self._moveToFirstStep(card, conf)
----

The card is moved back to the first step:

[source,python]
----
class Scheduler:

    def _moveToFirstStep(self, card, conf):
        card.left = self._startingLeft(card) # <1>

        # relearning card?
        if card.type == 3:
            self._updateRevIvlOnFail(card, conf) # <2>

        return self._rescheduleLrnCard(card, conf) # <3>

    def _updateRevIvlOnFail(self, card, conf):
        card.ivl = self._lapseIvl(card, conf)

    def _lapseIvl(self, card, conf):
        ivl = max(1, conf['minInt'], int(card.ivl*conf['mult']))
        return ivl

    def _rescheduleLrnCard(self, card, conf, delay=None):
        # normal delay for the current step?
        if delay is None:
            delay = self._delayForGrade(conf, card.left)

        card.due = int(time.time() + delay)
        card.queue = 1
        return delay

    def _delayForGrade(self, conf, left): # <4>
        left = left % 1000
        delay = conf['delays'][-left]
        return delay*60
----
<1> We restore the attribute `left` as if the card were new.
<2> We process lapses differently. By default, we reset the attribute `ivl` to `1` (next review in one day).
<3> The card due date is determined by adding the next step to the current date. The card remains in the learning queue (`1`).
<4> The method `_delayForGrade()` is a helper method to get the next step interval. The method extracts the number of remaining steps from the attribute `left` (Ex: `1002` => 2 remaining steps) and uses the setting `delay` to find the matching delay (Ex: `1m 10m 1d` => next study in `10m`).


#### After pressing "Hard"...

[source,python]
----
self._repeatStep(card, conf)
----

The current card step is repeated. This means the attribute `left` is unchanged. We still have the same number of remaining steps before graduation. The difference is that the card will be rescheduled in a delay slightly longer than the previous one. We average the last and next delays (Ex: `1m 10m 20m` and we are at the step 2 => repeat in `15m`).

[source,python]
----
class Scheduler:

    def _repeatStep(self, card, conf):
        delay = self._delayForRepeatingGrade(conf, card.left)
        self._rescheduleLrnCard(card, conf, delay=delay) # <1>

    def _delayForRepeatingGrade(self, conf, left):
        # halfway between last and next
        delay1 = self._delayForGrade(conf, left)
        delay2 = self._delayForGrade(conf, left-1)
        avg = (delay1+max(delay1, delay2))//2
        return avg
----
<1> We reuse the method `_rescheduleLrnCard()` introduced just before to update the card's due date.


#### After pressing "Good"...

[source,python]
----
# graduation time?
if (card.left%1000)-1 <= 0:
    self._rescheduleAsRev(card, conf, False)
else:
    self._moveToNextStep(card, conf)
----

The decision depends on if there are remaining steps or not:

_Case 1_: If we have finished the last step, the card is graduated to the learning queue:

[source,python]
----
class Scheduler:

    def _rescheduleAsRev(self, card, conf, early):
        lapse = card.type == 2

        if lapse:
            self._rescheduleGraduatingLapse(card) # <1>
        else:
            self._rescheduleNew(card, conf, early) # <2>

    def _rescheduleGraduatingLapse(self, card):
        card.due = self.today+card.ivl
        card.type = card.queue = 2

    def _rescheduleNew(self, card, conf, early):
        card.ivl = self._graduatingIvl(card, conf, early)
        card.due = self.today+card.ivl
        card.factor = conf['initialFactor']
        card.type = card.queue = 2

    def _graduatingIvl(self, card, conf, early):
        if card.type in (2,3):
            return card.ivl
        if not early: # <3>
            # graduate
            ideal =  conf['ints'][0]
        else:
            # early remove
            ideal = conf['ints'][1]
        return ideal
----
<1> When a lapse is graduated, we add the previous interval to the current date to determine the due date.
<2> When a new card is graduated, we initialize the two key attributes relative to the SRS algorithm: the ease factor and the interval. These fields will be necessary to determine the next due date for review cards.
<3> When graduating a new card, the initial interval will be different if we are completed all steps ("Good") or if we have pressed ("Easy") to immediately graduate the card (1 vs 4 days by default).

_Case 2_: If there are remaining steps:

[source,python]
----
class Scheduler:

    def _moveToNextStep(self, card, conf):
        # decrement real left count and recalculate left today
        left = (card.left % 1000) - 1
        card.left = self._leftToday(conf['delays'], left)*1000 + left # <1>

        self._rescheduleLrnCard(card, conf)
----
<1> The attribute `left` is updated to decrement the number of remaining steps and to recalculate the number of studies until the next day.

#### After pressing "Easy"...

[source,python]
----
self._rescheduleAsRev(card, conf, True)
----

The card is graduated to the review queue similarly to when we complete every step. The only exception is that the initial interval will be larger as explained in the previous point.


### Part 5.3: Answering Review Cards

[source,python]
----
class Scheduler:

   def _answerRevCard(self, card, ease):
        if ease == 1:
            self._rescheduleLapse(card)
        else:
            self._rescheduleRev(card, ease)
----

#### After pressing "Again"...

[source,python]
----
class Scheduler:

    def _rescheduleLapse(self, card):
        conf = self.col.deckConf["lapse"]

        card.lapses += 1 # <1>
        card.factor = max(1300, card.factor-200) # <2>

        suspended = self._checkLeech(card, conf) # <3>

        if not suspended:
            card.type = 2
            delay = self._moveToFirstStep(card, conf) # <4>
        else:
            # no relearning steps
            self._updateRevIvlOnFail(card, conf) # <5>
            delay = 0

        return delay

    # Leeches
    ##########################################################################

    def _checkLeech(self, card, conf):
        if card.lapses >= conf['leechFails']:
            # add a leech tag
            f = card.note
            f.addTag("leech")
            # Suspend
            card.queue = -1
            return True
----
<1> The number of lapses for this card is increased.
<2> The ease factor is reduced by 0.2 (but no lower than 1.3 as recommended by SM-2).
<3> If the number of lapses reaches the value of the setting `leechFails`, the card is marked as a leech. A tag is added to the note and the card is moved to the queue `-1` (= suspended). The card will therefore be ignored when filling the different queue as no method `_fillXXX()` considers cards in the queue `-1`.

#### After pressing "Hard," "Good," "Easy"...

The card will be rescheduled in an "ideal" number of days. In practice, most cards reside in the learning queue, and the "Again" button is pressed rarely. This means the core logic of the Anki SRS algorithm is determined by the following methods.

[source,python]
----
class Scheduler:

    def _rescheduleRev(self, card, ease):
        # update interval
        self._updateRevIvl(card, ease) # <1>

        # then the rest
        card.factor = max(1300, card.factor+[-150, 0, 150][ease-2]) # <2>
        card.due = self.today + card.ivl

    def _updateRevIvl(self, card, ease):
        card.ivl = self._nextRevIvl(card, ease)

    # Interval management
    ##########################################################################

    def _nextRevIvl(self, card, ease): # <3>
        "Next review interval for CARD, given EASE."
        delay = self._daysLate(card)
        conf = self.col.deckConf["rev"]
        fct = card.factor / 1000
        hardFactor = conf.get("hardFactor", 1.2)
        if hardFactor > 1:
            hardMin = card.ivl
        else:
            hardMin = 0
        ivl2 = self._constrainedIvl(card.ivl * hardFactor, conf, hardMin)
        if ease == 2:
            return ivl2

        ivl3 = self._constrainedIvl((card.ivl + delay // 2) * fct, conf, ivl2)
        if ease == 3:
            return ivl3

        ivl4 = self._constrainedIvl(
            (card.ivl + delay) * fct * conf['ease4'], conf, ivl3)
        return ivl4

    def _daysLate(self, card):
        "Number of days later than scheduled."
        return max(0, self.today - card.due)

    def _constrainedIvl(self, ivl, conf, prev):
        ivl = max(ivl, prev+1, 1)
        ivl = min(ivl, conf['maxIvl'])
        return int(ivl)
----
<1> The attribute `ivl` determines the next due date (we add it to the current date to determine the value of the attribute `due`).
<2> The ease factor is changed by removing 0.15 for "Hard" cards or by adding 0.15 for "Easy" cards. The ease factor is left unchanged for "Good" cards. Only their intervals will be changed to increase the period between studies.
<3> The method `_nextRevIvl()` determine the next interval:
* "Hard": the current interval is multiplied by the value of the hard interval (1.2 by default).
* "Good": the current interval is multiplied by the current ease (+ a bonus if the card was late).
* "Easy": the current interval is multiplied by the current ease times the easy bonus (1.3 by default) (+ a bonus if the card was late).


**We are done** ðŸŽ‰. The complete code is available in the link:https://github.com/julien-sobczak/anki-srs-under-the-hood/blob/main/anki/schedv2_minimal_v3.py[companion GitHub repository]. A more complete link:https://github.com/julien-sobczak/anki-srs-under-the-hood/blob/main/anki/schedv2_annotated.py[annotated version] is also available in the same repository including two additional features described next.



=== Bonus: Day Boundaries

link:https://docs.ankiweb.net/deck-options.html?#day-boundaries[Anki treats small steps and steps that cross a day boundary differently]. With small steps, the cards are shown as soon as the delay has passed, in preference to other due cards in review. This is done so that you can answer the card as closely to the calculated delay as possible. In contrast, if the interval crosses a day boundary, it is automatically converted to days.

In the implementation, the code splits the learning queue into two distinct queues: sub-day learning and day learning.

[source,python]
----
# ...

def _resetLrn(self):
    self._lrnQueue = []
    self._lrnDayQueue = [] # <1>

# ...

def _rescheduleLrnCard(self, card, conf, delay=None):
    # normal delay for the current step?
    if delay is None:
        delay = self._delayForGrade(conf, card.left)

    card.due = int(time.time() + delay)
    # due today?
    if card.due < self.dayCutoff: # <2>
        card.queue = 1
    else:
        # the card is due in one or more days, so we need to use the
        # day learn queue
        ahead = ((card.due - self.dayCutoff) // 86400) + 1
        card.due = self.today + ahead
        card.queue = 3

# ...

def _getCard(self):
    # learning card due?
    c = self._getLrnCard() # <3>
    if c:
        return c

    # new first, or time for one?
    if self._timeForNewCard():
        c = self._getNewCard()
        if c:
            return c

    # card due for review?
    c = self._getRevCard()
    if c:
        return c

    # day learning card due?
    c = self._getLrnDayCard() # <3>
    if c:
        return c

    # new cards left?
    c = self._getNewCard()
    if c:
        return c

    # collapse or finish
    return self._getLrnCard(collapse=True)
----
<1> The previous queue is split into two queues:
* `_lrnQueue` (`queue == 1`) = sub-day learning queue
* `_lrnDayQueue` (`queue == 3`) = day learning queue

<2> Learning cards are rescheduled in the sub-day queue `1` when the next review is planned before the end of the day review session. The due date is the number of seconds until the next review. Otherwise, the card is rescheduled in the day learning queue `3` and the delay is the number of days until the next review.

<3> Sub-day learning cards are prioritized first to be sure to review them as close as their delay in seconds. Day learning cards are reviewed last since their delay in days tolerates more flexibility (reviewing them the next day is not as bad as for sub-day learning cards).


=== Bonus: Fuzzing

When you select an ease button on a review card, link:https://docs.ankiweb.net/studying.html#fuzz-factor[Anki also applies a small amount of random â€œfuzzâ€] to prevent cards that were introduced at the same time and given the same ratings from sticking together and always coming up for review on the same day.

Here is the code:

[source,python]
----
def _fuzzedIvl(self, ivl): # <1>
    min, max = self._fuzzIvlRange(ivl)
    return random.randint(min, max)

def _fuzzIvlRange(self, ivl):
    if ivl < 2:
        return [1, 1]
    elif ivl == 2:
        return [2, 3]
    elif ivl < 7: # <2>
        fuzz = int(ivl*0.25)
    elif ivl < 30: # <2>
        fuzz = max(2, int(ivl*0.15))
    else: # <2>
        fuzz = max(4, int(ivl*0.05))
    # fuzz at least a day
    fuzz = max(fuzz, 1)
    return [ivl-fuzz, ivl+fuzz]
----
<1> The function `_fuzzedIvl()` is only called for intervals greater than one day. For sub-day learning cards introduced in the previous point, fuzzing is also applied up to 5 minutes:
+
[source,python]
----
maxExtrax = min(300, int(delay*0.25))
fuzz = random.randrange(0, maxExtra)
----
<2> The fuzz factor is reduced but the fuzzing increases as intervals become larger.



== A Better Anki SRS Algorithm?

The link:http://www.supermemo.com/english/ol/sm2.htm[SM-2 algorithm], on which Anki is based, was released in 1987 in SuperMemo 1.0. It was revised several times since:

* link:http://super-memory.com/english/ol/sm4.htm[SM-4] (1989)
* link:http://super-memory.com/english/ol/sm5.htm[SM-5] (1989)
* link:http://super-memory.com/english/ol/sm6.htm[SM-6] (1991)
* link:http://super-memory.com/english/algsm8.htm[SM-8] (1995)
* link:http://super-memory.com/english/algsm11.htm[SM-11] (2002)
* link:http://super-memory.com/english/algsm15.htm[SM-15] (2011)
* link:https://supermemo.guru/wiki/Algorithm_SM-17[SM-17] (2015)
* link:https://supermemo.guru/wiki/Algorithm_SM-18[SM-18] (2019)

Each version iterates over deficiencies of the previous one.
You can find a link:https://supermemo.guru/wiki/History_of_SuperMemo_algorithm[short summary] of the main changes or a (very) link:https://www.supermemo.com/fr/articles/history[long summary] of the history of SuperMemo. The short version is probably too terse to understand the improvements, and the long version is probably too detailed to understand everything. (It took me more than 5 hours to read it but it was worth the reading!)

[quote, Piotr Wozniak, Original author of SuperMemo]
____
SuperMemo 2 was great. Its simple algorithm has survived in various mutations to this day in popular apps such as Anki or Mnemosyne. However, the algorithm was dumb in the sense that there was no way of modifying the function of optimum intervals. The findings of 1985 were set in stone. Memory complexity and stability increase were expressed by the same single number: E-factor. It is a bit like using a single lever in a bike to change gears and the direction of driving.
____

From a high-level perspective, the main motivation for every version is to determine better optimal intervals (= the ideal periods between reviews of a single card) so that the forgetting index is close to 10% (= recall of 90% is acceptable).

From a low-level perspective, several approaches were experimented by SuperMemo. The first major version (SM-2) introduced the ease factor to capture the difficulty of an item (the lower the ease factor = the more difficult = the shorter the interval). The ease factor was multiplied by the previous interval to determine the next interval.

The successive iterations become more and more elaborate by adding new dimensions, in particular, what is called by SuperMemo the link:https://supermemo.guru/wiki/Two_component_model_of_memory[two-component model]: *stability* and *retrievability* (in complement to *difficulty* represented by the E-Factor). Stability tells you how long a piece of knowledge can last in memory. Retrievability tells you how easy it is to recall a piece of knowledge. These notions may appear similar but they aren't. "If you take two memories right after a review, one with a short optimum interval, and the other with a long optimum interval, the memory status of the two must differ," declares Piotr Wozniak, "Both can be recalled perfectly (maximum retrievability) and they also need to differ in how long they can last in memory (different stability)."

What follows is an example of the optimum factors (OF) matrix used in SM-4/SM-5. The matrix ignores the retrievability dimension, which was introduced in SM-6.

image::sm-5-matrix.png[width=700, link="/posts_resources/2022-05-30-anki-srs/sm-5-matrix.png"]

A two-dimensional matrix is easier to represent but the logic is similar with more dimensions. Initially, the matrix was defined based on prior measurements in SuperMemo. After each answer, the grade tells SuperMemo how well the interval "performed." If the grade is low, the interval was too long. If the grade is high, the interval was too short. The entry in the matrix is updated in consequence and matrix smoothing is applied (= if a value increases, a smaller increase can be beneficial to neighbors too).

The two-component model of long-term memory still represents the foundation of SuperMemo since its introduction in SM-4 in 1989. link:http://super-memory.com/articles/kowal.htm[Piotr Wozniak was pessimistic about a better, faster, and more effective algorithm] as soon as 1994. The versions of the algorithm that appeared after that didn't introduce a breakthrough improvement like SuperMemo did when it abandoned the SM-2 algorithm in 1989, the same algorithm that keeps popping up in new applications.


[NOTE]
."New" Applications
====
Many applications relying on SRS appeared in popular app stores more or less recently: link:https://quizlet.com/[Quizlet], link:https://www.memrise.com/[Memrise], link:https://www.duolingo.com/[Duolingo], link:https://www.lingodeer.com/[LingoDeer], link:https://www.brainscape.com/[Brainscape], link:https://lingvist.com/[Lingvist], link:https://chegg.com[Chegg], link:https://www.remnote.com/[RemNote], link:https://mochi.cards/[Mochi], link:https://www.memcode.com/[Memcode], ...

* link:https://mochi.cards/docs/#spaced-repetition[__Mochi__'s algorithm] is very simple. The card interval is doubled after each correct answer, and cut in half otherwise.

* link:https://memrise.zendesk.com/hc/en-us/articles/360015889057-How-does-the-spaced-repetition-system-work-[__Memrise__'s algorithm] is similar to _Mochi_'s. The card interval increases using the following steps: 4 hours, 12 hours, 24 hours, 6 days, 12 days, 48 days, 96 days, and 6 months. Any wrong answer moves back the card to the first interval.

* link:https://quizlet.com/blog/spaced-repetition-for-all-cognitive-science-meets-big-data-in-a-procrastinating-world[Quizlet's algorithm] has known several iterations. The first implementation simply repeats all the questions you got wrong. The second implementation is similar to Anki where the card interval increases by approximately 2.2 and wrong answers reset the interval to one day. The next implementation relies on machine learning and uses the millions of answers to determine the recall probability, which is the chance you answer correctly. This allows, for example, to reduce the interval for words with irregular spellings when learning a foreign language.

* link:https://blog.duolingo.com/how-we-learn-how-you-learn/[__Duolingo__'s algorithm] is similar to Quizlet. Duolingo has millions of students who generate billions of statistics about language learning every day. Like Quizlet, Duolingo uses machine learning to predict how likely you are to remember any given word at any time. This is represented by the strength meter (still strong, pretty good, time to practice, overdue) below every lesson.

* link:https://www.youtube.com/watch?v=IwaoV-C9az8&ab_channel=RemNote[RemNote's algorithm] is customizable like Anki and most settings will look familiar to Anki users, especially after following this tutorial.

* link:https://news.ycombinator.com/item?id=23948541[Memcode's algorithm] also uses SM-2.
====

In my opinion, *Anki is not perfect but there is no need to focus too much on optimizing it*:

* **Adding more dimensions**? What if you review inadvertently a card, for example when explaining the idea to a coworker. No algorithm can exploit this and postpone the next review. *No algorithm will ever be perfect*.
* **Using machine learning**? Applying the lessons from other learners is great for common datasets. For example, if most French users have trouble learning a particular English word, chances are future French users will need shorter intervals too. But what about custom-edited cards about subjects such as science, management, and parenting. What about your interest in any of these subjects. We remember more easily what passionates us. **Machine learning excels when there are patterns but learning is profoundly a personal, unique experience**.

Therefore, *I think we should focus more on optimizing our practices rather than the tools*. Here are two key practices:

* *Devote time to understand*. Learning is a 3-steps process: encoding, storage, and retrieval. Anki helps to store information for a longer period by reviewing it ("use it or lose it"). But Anki is dependent on how good the encoding happened. You cannot learn something you haven't understood first. Therefore, you must devote (a lot of) time link:https://www.juliensobczak.com/write/2018/12/01/10-rules-for-better-flashcards.html[writing your own flashcards]. *A poor encoding process will make the best SRS algorithm useless.*

* *Devote time to learn*. Trying Anki is easy. Sticking to it is hard. Many users quickly abandon Anki probably because its benefits can only be visible after several years of making it a habit. And everyone knows changing habits is hard, otherwise _Atomic Habits_ would not be the #1 best-selling book on Amazon last year. *A lack of motivation will make the best SRS algorithm useless.*

One last important thing,

[quote, Piotr Wozniak]
____
Learning is one of the most enjoyable things in the world.
____


[NOTE.remember]
.To Remember
====
* *A Spaced Repetition System (SRS) counteracts the effect of the forgetting curve*. Memory decay is inevitable but can be influenced.
* *SRS systems can be implemented with or without a computer*. The Leitner system remains popular.
* *SRS systems often target a retention close to 90%* (= 10% of cards are wrongly answered).
* *SuperMemo* introduced the first *SRS algorithm running on a computer* (SM-2).
* *SM-2 continues to be used by most applications* including Anki, despite having been abandoned in SuperMemo three decades ago.
* *Anki makes the SM-2 highly configurable* and uses different queues to manage cards differently based on if they are new, in learning, or simply in review.
* *Most algorithms use the item difficulty* (known as the ease factor) to determine optimal intervals. SuperMemo goes well beyond and also uses memory stability and memory retrievability.
* *Recent SRS applications rely on machine learning* to exploit the specificities of the learning materials (ex: English words with irregular syntax) and to use the information collected from their massive dataset of users to tune their algorithm. SuperMemo never chose this approach.
* *The perfect SRS algorithm will never exist*. No algorithm can determine if you are passionate about a subject, or if you review by chance the content of a card at work during a discussion with a coworker (in which case an "ideal" algorithm must postpone the next review).
* *Creating great flashcards and making reviewing them a habit have probably a far bigger impact* than any improvement in the SRS algorithm you use.
====



== Additional Links

* The link:https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html[Anki Website] explains succinctly the main differences between its algorithm and SM-2.
* link:https://github.com/ankidroid/Anki-Android/wiki/Database-Structure[Anki Database Structure]: The most up-to-date guide to the Anki internal database schema, which was more than useful during the writing of this article.
* link:https://web.archive.org/web/20200926103540/https://massimmersionapproach.com/table-of-contents/anki/low-key-anki/the-ease-factor-problem/[The Ease Factor Problem]: Interesting insight about the impact of changing the ease factor after a lapse.
* link:https://www.youtube.com/watch?v=1XaJjbCSXT0[A great video] to introduce most of the notions covered in the Anki section.
* Last but not least, link:https://www.supermemo.com/en/articles/history[the true history of spaced repetition]: An extensive coverage of the subject by Piotr Wozniak. A reference.



////

https://help.supermemo.org/wiki/Glossary

* **A-Factor** (absolute factor; AF): number associated with every element in a collection. A-Factor determines how much intervals increase in the learning process. The higher the A-Factor, the faster the intervals increase. A-Factors reflect item difficulty. The higher the A-Factor the easier the item. The most difficult items have A-Factors equal to 1.2. A-Factor is defined as the quotient of the second optimum interval and the first optimum interval used in repetitions.

* **D-Factor** decline of O-Factors with successive repetitions can be approximated with a power curve that begins at O-Factor that equals A-Factor. D-Factors are no longer used in SuperMemo Algorithm. When a power regression is used to compute O-Factors on the basis of R-Factors for successive repetitions in a single A-Factor category, the decay constant of the resulting function is called a D-Factor. The larger the D-Factor the faster the decline of O-Factors with each repetition. This means that large D-Factors imply more frequent repetitions. D in D-Factor stands for decay (it is a decay constant of the negative power function).

* **E-Factor** (easiness factor; EF) is the number related to the difficulty of a given element in early versions of SuperMemo (up to and including SuperMemo 7). New inter-repetition intervals were determined by multiplying the old interval by E-Factor.

* **matrix smoothing** is a mathematical procedure that converts a matrix of numbers into a "smoother version" (e.g. by averaging the neighboring entries). For example, if the row of the matrix is 1, 2, 3, 4, 666, 6, 7, 8, smoothing might convert it to 1, 2, 3, 6, 99, 9, 8.

* **O-Factor** (optimum factor; OF) is a number which tells you how much intervals should increase to reach recall of 90%. O-Factors differ for different levels of memory stability and different item difficulty. They are normalized for the forgetting index of 10%. For the first repetition, i.e. there was no prior interval, O-Factor is assumed to be the same as the first interval (as if the prior interval was 1 day). For the first repetition, different O-Factors are computed for a different number of memory lapses. For example: if the O-Factor is 2.5, and the prior interval was 20 days, at repetition time, the new interval should be set to 2.5*20 days, i.e. 50 days.

* **OF matrix** is athe matrix of O-Factors for different levels of difficulty (expressed as A-Factor) and stability (expressed as repetition category). The OF matrix is used by SuperMemo Algorithms SM-5 through SM-15 in computing optimum intervals in spaced repetition. In the newest algorithms, the role of the 2-dimensional OF matrix is played by the 3-dimensional SInc[] matrix (with the added dimension of retrievability).

* **R-Factor** (retention factor; RF) is the number which says at which U-Factor (i.e. the measure of interval increase) the measured forgetting index (i.e. the measure of forgetting) is approximated to be 10%. This number is unique for different item difficulties and for different repetition categories (i.e. the measure of memory stability). R-Factors can be seen as a vertical green line on forgetting curve graphs in SuperMemo.

* **U-Factor** is the number associated with each memorized element. It equals to the ratio of the current interval and the previously used interval. If the element has not been repeated yet, i.e. the previous interval is not defined, U-Factor equals the first interval. The greater the U-Factor the greater the increase of the interval between repetitions. For items, U-Factors are determined by SuperMemo Algorithm. For topics, U-Factors are determined by A-Factors.


////////////
Appendixes
////////////


### SRS Applications


[quote, Mochi Documentation]
____
link:https://mochi.cards/docs/#spaced-repetition[Mochi's algorithm] is very simple. Each time you remember a card, the time it takes before it's reviewed again doubles. When a card is forgotten that time is cut in half. These settings can be tweaked in the settings, and different decks can have their own settings.
____

[quote, Mochi Documentation]
link:https://mochi.cards/faq.html[Which spaced repetition algorithim does Mochi use?]
Mochi uses a modified SM-2 algorithim. Modified in that 1. the easing factor must be adjusted by the user manually and 2. cards do not reset their repetition interval on an incorrect answer by default."
____

[quote, Memrise]
____
The link:https://memrise.zendesk.com/hc/en-us/articles/360015889057-How-does-the-spaced-repetition-system-work-[Memrise algorithm] predicts when any given word or sentence is likely to fall out of your long-term memory and it's time for you to review it. This is based on a learning technique called the spaced repetition system, which leads to stronger memories.

When reviewing a word or sentence correctly, the item will be moved to a longer interval. The review schedule is as follows:

Next review in: 4 hours > 12 hours > 24 hours > 6 days > 12 days > 48 days > 96 days > 6 months

If you get an item wrong during a review, it will be moved back to the first interval (i.e. to be reviewed in 4 hours).
____

[quote, Quizlet Documentation]
____
Long-Term Learning used a standard spaced repetition algorithm, similar to SuperMemo or Anki. It works something like this:

* Introduce a few new terms each day
* Study all of the dayâ€™s terms until you get them all correct, then study the new terms again the next day
* Each time a term is answered correctly, increase the delay until itâ€™s studied again by a little * more than double (Study 1 day later, 3 days after that, then 7 days, 16 days, etc.)
* If a term is answered incorrectly, start over and reset the delay for that term to 1 day.
____


### UI

image::anki-preferences-scheduling.png[]

* â˜‘ Show next review time above answer buttons (default: yes)
* â˜‘ Show remaining card count during reviews (default: yes)
* â˜‘ï¸ Show learning cards with larger steps before reviews (default: no)
* â˜‘ Legacy timezone handling (buggy, but required for AnkiDroid <= 2.14) (default: no)
* â˜‘ V3 scheduler (beta) (default: no)
* Select:
** "Mix new cards and reviews" (default)
** "Show new cards after reviews"
** "Show new cards before reviews"
* Next day starts at `value` hours past midnight (default: `4`)
* Learn ahead limit `value` mins (default: `20`)
* Timebox time limit `value` mins (default: `0`)

image::anki-deck-options-scheduling.png[]

See `anki/ftl/core/deck-config.ftl`

* Daily Limits
** New cards/day: `value` (default `20`)
*** â„¹: The maximum number of new cards to introduce in a day, if new cards are available. Because new material will increase your short-term review workload, this should typically be at least 10x smaller than your review limit.
** Maximum reviews/day: `value` (default `50`)
*** â„¹: The maximum number of review cards to show in a day, if cards are ready for review.

* New Cards
** Learning steps (default `1m 10m`)
*** â„¹: One or more delays, separated by spaces. The first delay will be used when you press the `Again` button on a new card, and is 1 minute by default. The `Good` button will advance to the next step, which is 10 minutes by default. Once all steps have been passed, the card will become a review card, and will appear on a different day. Delays are typically minutes (eg `1m`) or days (eg `2d`), but hours (eg `1h`) and seconds (eg `30s`) are also supported.
** Graduating interval (default `1`)
*** â„¹: The number of days to wait before showing a card again, after the `Good` button is pressed on the final learning step.
** Easy interval (default `4`)
*** â„¹: The number of days to wait before showing a card again, after the `Easy` button is used to immediately remove a card from learning.
** Insertion order: `Sequential`, `Random` (default `???`)
*** â„¹: Controls the position (due #) new cards are assigned when you add new cards. Cards with a lower due number will be shown first when studying. Changing this option will automatically update the existing position of new cards.

* Lapses
** Relearning steps (default `10m`)
*** â„¹: Zero or more delays, separated by spaces. By default, pressing the `Again` button on a review card will show it again 10 minutes later. If no delays are provided, the card will have its interval changed, without entering relearning.
** Minimum interval (default `1`)
*** â„¹: The minimum interval given to a review card after answering `Again`.
** Leech threshold (default `8`)
*** â„¹: The number of times `Again` needs to be pressed on a review card before it is marked as a leech. Leeches are cards that consume a lot of your time, and when a card is marked as a leech, it's a good idea to rewrite it, delete it, or think of a mnemonic to help you remember it.
** Leech action: "Suspend Card" (default) or "Tag Only"
*** â„¹: `Tag Only`: Add a "leech" tag to the note, and display a pop-up. `Suspend Card`: In addition to tagging the note, hide the card until it is manually unsuspended.

* Timer
** Maximum answer seconds (default `60`)
*** â„¹: The maximum number of seconds to record for a single review. If an answer exceeds this time (because you stepped away from the screen for example), the time taken will be recorded as the limit you have set.
** Show answer time: on/off (default off)
*** â„¹: In the review screen, show a timer that counts the number of seconds you're taking to review each card.

* Burying
** Bury new siblings until the next day: on/off (default on)
*** â„¹: Whether other cards of the same note (eg reverse cards, adjacent cloze deletions) will be delayed until the next day.
** Bury review siblings until the next day: on/off (default on)
*** â„¹: Whether other cards of the same note (eg reverse cards, adjacent cloze deletions) will be delayed until the next day.

* Audio
** Don't play audio automatically: on/off (default off)
** Skip question when replaying answer: on/off (default off)
*** â„¹: Whether the question audio should be included when the Replay action is used while looking at the answer side of a card.

* Advanced
** Maximum interval (default `36500`)
*** â„¹: The maximum number of days a review card will wait. When reviews have reached the limit, `Hard`, `Good` and `Easy` will all give the same delay. The shorter you set this, the greater your workload will be.
** Starting ease  (default `2.50`)
*** â„¹: The ease multiplier new cards start with. By default, the `Good` button on a newly-learned card will delay the next review by 2.5x the previous delay.
** Easy bonus  (default `1.30`)
*** â„¹: An extra multiplier that is applied to a review card's interval when you rate it `Easy`.
** Interval modifier (default `1.00`)
*** â„¹: This multiplier is applied to all reviews, and minor adjustments can be used to make Anki more conservative or aggressive in its scheduling. Please see the manual before changing this option.
** Hard interval (default `1.20`)
*** â„¹: The multiplier applied to a review interval when answering `Hard`.
** New interval  (default `0.00`)
*** â„¹: The multiplier applied to a review interval when answering `Again`.

////
